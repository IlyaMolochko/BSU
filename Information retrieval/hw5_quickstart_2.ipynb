{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "hw5_quickstart.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHG5cnj-mSLr"
      },
      "source": [
        "## Домашнее задание 5\n",
        "\n",
        "В данном домашнем задании Вам предстоит реализовать автоматическое исправление опечаток в запросах пользователей. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnxxw7z4mSLz"
      },
      "source": [
        "### 1. Датасет\n",
        "Для оценки качества алгоритма исправления опечаток, Вам предоставляется файл `queries.tsv.gz`. В каждой строке файла записаны два запроса – исходный и исправленный. Для простоты, оба запроса будут иметь одинаковое количество слов и отличаться незначительно. Зачастую исходный и исправленный запрос совпадают, что означает что исправлять такой запрос не требуется."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj25ZsR4mZ_G",
        "outputId": "bee051ea-d100-4a12-a2b3-ebeb8536aebe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE7b5z1YmSL6"
      },
      "source": [
        "from typing import List, Tuple, Generator, Callable\n",
        "\n",
        "Query = str\n",
        "Sentence = str\n",
        "Filename = str\n",
        "Word = str\n",
        "Queries = List[Tuple[Query, Query]]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2o0Ky6FmSL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d1a7be-de5f-4d36-9490-37b0545cf8e1"
      },
      "source": [
        "from termcolor import colored\n",
        "import difflib\n",
        "\n",
        "def diff_queries(original: Query, fixed: Query) -> Query:\n",
        "    result = ''\n",
        "    for pos, d in enumerate(difflib.ndiff(original, fixed)):\n",
        "        if d[0] == '+':\n",
        "            result += colored(d[2], 'green')\n",
        "        elif d[0] == '-':\n",
        "            result += colored(d[2], 'red')\n",
        "        else:\n",
        "            result += d[2]\n",
        "    return result\n",
        "\n",
        "print(diff_queries(\"lake compond the park\", \"lake compound the park\"))\n",
        "print(diff_queries(\"traditional chothes\", \"traditional clothes\"))\n",
        "print(diff_queries(\"jack sparrow\", \"captain jack sparrow\"))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lake compo\u001b[32mu\u001b[0mnd the park\n",
            "traditional c\u001b[31mh\u001b[0m\u001b[32ml\u001b[0mothes\n",
            "\u001b[32mc\u001b[0m\u001b[32ma\u001b[0m\u001b[32mp\u001b[0m\u001b[32mt\u001b[0m\u001b[32ma\u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32m \u001b[0mjack sparrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a8zjU7fmSL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204022f5-0773-439f-b80e-a0134ce22ed0"
      },
      "source": [
        "import gzip\n",
        "\n",
        "def load_queries(fn: Filename) -> Queries:\n",
        "    result = []\n",
        "    with gzip.open(fn, 'rt', encoding='utf8') as inp:\n",
        "        for line in inp:\n",
        "            original, fixed = line.rstrip('\\n').split('\\t')\n",
        "            result.append((original, fixed))\n",
        "    return result\n",
        "\n",
        "queries = load_queries(\"./drive/MyDrive/queries.tsv.gz\")\n",
        "print(f'Loaded {len(queries)} queries\\n')\n",
        "for original, fixed in queries[10:20]:\n",
        "    print(diff_queries(original, fixed))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 102436 queries\n",
            "\n",
            "emb\u001b[31me\u001b[0m\u001b[32ma\u001b[0mr\u001b[31mi\u001b[0m\u001b[32mr\u001b[0m\u001b[32ma\u001b[0mssing red carpet moments\n",
            "grants for rural areas flo\u001b[32mr\u001b[0mi\u001b[31mr\u001b[0mda\n",
            "the home \u001b[31mh\u001b[0m\u001b[32md\u001b[0mepot merchandising\n",
            "delaware motorcycle inspectio\u001b[32mn\u001b[0m requirements\n",
            "highland park hospital gastric b\u001b[31mi\u001b[0m\u001b[32my\u001b[0mpass surgery\n",
            "grand the\u001b[31mi\u001b[0mft auto\n",
            "windward community college\n",
            "my credit reports\n",
            "st\u001b[32mr\u001b[0mack intermediate school\n",
            "mongol empire political system\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_15jNn5mSL9"
      },
      "source": [
        "queries_sample = [\n",
        "    (\"grand theift auto\", \"grand theft auto\"),\n",
        "    (\"belarus longitude and latitdue\", \"belarus longitude and latitude\"),\n",
        "    (\"search for poeoms\", \"search for poems\"),\n",
        "    (\"large guacolmoi dip restaurtant price\", \"large guacamole dip restaurant price\"),\n",
        "    (\"texas chainsaw mascurer\", \"texas chainsaw massacre\"),\n",
        "    (\"royal trump subtitle\", \"royal tramp subtitle\"),\n",
        "    (\"florida fiberglass polls\", \"florida fiberglass pools\"),\n",
        "    (\"how to make a calender\", \"how to make a calendar\"),\n",
        "    (\"university of south caroline\", \"university of south carolina\"),\n",
        "    (\"maureen mcdonald in virginia\", \"maureen mcdonnell in virginia\"),\n",
        "]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TIi48h5mSL_"
      },
      "source": [
        "Для составления словаря и обучения языковых моделей Вам предоставляется небольшой корпус текста, неслучайная выборка из большой английской википедии в файле `train.bz2`. Этот файл содержит примерно 5 млн строк или 80 млн слов. Каждая строка – одно предложение без знаков препинания.\n",
        "Использование других словарей и корпусов запрещено."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBlMvLp4mSMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b8db8dd-6af8-4fcd-bd83-a7b1572cf5d9"
      },
      "source": [
        "import bz2\n",
        "from tqdm import tqdm\n",
        "\n",
        "def read_huge_corpus(fn: Filename) -> Generator[Sentence, None, None]:\n",
        "    with bz2.open(fn, 'rt', encoding='utf8') as inp:\n",
        "        for line in tqdm(inp):\n",
        "            yield line.rstrip('\\n')\n",
        "\n",
        "for li, line in enumerate(read_huge_corpus(\"./drive/MyDrive/train.bz2\")):\n",
        "    print(line)\n",
        "    if li == 10:\n",
        "        break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10it [00:00, 259.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gol neshin\n",
            "mitochondrial dna depletion syndrome mds or mdds is any of a group of autosomal recessive disorders that cause a significant drop in mitochondrial dna in affected tissues\n",
            "following the relegation of sc freiburg in 2005 he was on the verge of signing for metalurg donetsk but instead he accepted a contract with vfl wolfsburg\n",
            "the first issue for geometers is what kind of geometry is adequate for a novel situation\n",
            "cedar grove was formerly a stage and freight stop\n",
            "regular bus service runs from bhubaneswar to niali which is away\n",
            "later they were also known for the cream wafer biscuits\n",
            "strabomantis cornutus\n",
            "gtk+ scene graph kit gsk was initially released as part of gtk+ 3.90 in march 2017 and is meant for gtk-based applications that wish to replace clutter for their ui\n",
            "the match took place on 10 april 1906 at the hipódromo madrid\n",
            "the brothers came from fresno california\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yTnXP8QmSMC"
      },
      "source": [
        "### 2. Поиск близких слов\n",
        "Требуется научится быстро находить список из сотни слов, которые незначительно отличаются от заданного слова.\n",
        "\n",
        "Не стоит перебирать все слова словаря – займёт слишком много времени.\n",
        "\n",
        "Для ускорения перебора предлагается создать триграммный индекс – для каждой буквенной триграммы храним список слов, в которых она есть. Тогда для поиска похожих на данное слово найдем слова большим количеством совпадающих триграмм. \n",
        "\n",
        "Совет 1: стоит сделать отельный индекс для каждой длинны слова и использовать только те индексы, в которых лежат слова близкие по длине к исходному.\n",
        "\n",
        "Совет 2: для выделения триграмм стоит обрамить слово спецсимволом, чтобы триграммы на концах слова отличались от оных в середине.\n",
        "\n",
        "Любые другие алгоритмы, улучшающие качество за разумное время (хождение по бору с ошибками, перебор ошибок) – не возбраняются.\n",
        "\n",
        "Не побрезгуйте кешировать результат работы этого алгоритма, чтобы дальнейшая работа протекала быстрее."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wjc1AIczH-r"
      },
      "source": [
        "from collections import Counter\n",
        "from nltk import ngrams"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL1ehI5t4E1m",
        "outputId": "aa1a29eb-aa4e-43b6-9276-5584c91c2a9c"
      },
      "source": [
        "dct = Counter()\n",
        "words = []\n",
        "for li, line in enumerate(read_huge_corpus(\"./drive/MyDrive/train.bz2\")):\n",
        "    words += line.split()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4717753it [00:48, 97758.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1wdww84cnAa"
      },
      "source": [
        "dct = Counter([word.lower() for word in words])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npnJ-lhvoUYC"
      },
      "source": [
        "del words"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm3pFX3dcsGi",
        "outputId": "20782310-04a7-4bd4-f3f6-632bbf2a9f2a"
      },
      "source": [
        "len(dct)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1681973"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuZsRsNRd5nh"
      },
      "source": [
        "cnt = 0\n",
        "for i in dct:\n",
        "    if dct[i] <= 2:\n",
        "        cnt += 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAN7Vgf3eC7f",
        "outputId": "2489ad04-540c-41d8-8ef7-228ca89ba724"
      },
      "source": [
        "cnt"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1246761"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEf3mt8xgfx2"
      },
      "source": [
        "dct = {word:cnt for word, cnt in dct.items() if cnt >= 3}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tA03mVwg-C-",
        "outputId": "23a4d5c5-f3b2-45f4-84b5-d483bc5b711b"
      },
      "source": [
        "len(dct)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "435212"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYDmVSFP3LlP"
      },
      "source": [
        "def get_index(dct):\n",
        "    index = dict()\n",
        "    for word in tqdm(dct):\n",
        "        groups = index.get(len(word), dict())\n",
        "        for ngram in ngrams(f'${word}$', 3):\n",
        "            tgram = ''.join(ngram)\n",
        "            group = groups.get(tgram, [])\n",
        "            group.append(word)\n",
        "            groups[tgram] = group\n",
        "        index[len(word)] = groups\n",
        "    return index"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik4wJIjOhMpu",
        "outputId": "a36497fd-3204-4139-e678-5cb02086e2f7"
      },
      "source": [
        "index = get_index(dct)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 435212/435212 [00:05<00:00, 83570.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2Yah7fxmSME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f872040c-98db-4fc8-b6d8-8eb0acb2a78d"
      },
      "source": [
        "def extract_different_words(queries: Queries) -> List[Tuple[Word, Word]]:\n",
        "    words_to_fix = []\n",
        "    for original, fixed in queries:\n",
        "        if original != fixed:\n",
        "            for word_orig, word_fixed in zip(original.split(), fixed.split()):\n",
        "                if word_orig != word_fixed:\n",
        "                    words_to_fix.append((word_orig, word_fixed))\n",
        "    return words_to_fix\n",
        "                    \n",
        "words_to_fix = extract_different_words(queries)\n",
        "print(f'Found {len(words_to_fix)} words to fix')\n",
        "for original, fixed in words_to_fix[:10]:\n",
        "    print(diff_queries(original, fixed))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 53495 words to fix\n",
            "c\u001b[31mh\u001b[0m\u001b[32ml\u001b[0mothes\n",
            "catalog\u001b[31me\u001b[0ms\n",
            "compo\u001b[32mu\u001b[0mnd\n",
            "barn\u001b[32me\u001b[0ms\n",
            "emb\u001b[31me\u001b[0m\u001b[32ma\u001b[0mr\u001b[31mi\u001b[0m\u001b[32mr\u001b[0m\u001b[32ma\u001b[0mssing\n",
            "flo\u001b[32mr\u001b[0mi\u001b[31mr\u001b[0mda\n",
            "\u001b[31mh\u001b[0m\u001b[32md\u001b[0mepot\n",
            "inspectio\u001b[32mn\u001b[0m\n",
            "b\u001b[31mi\u001b[0m\u001b[32my\u001b[0mpass\n",
            "the\u001b[31mi\u001b[0mft\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY64Wv_imSMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46d9a86-5dd0-4a8d-834a-54d22a68518f"
      },
      "source": [
        "def find_similar_words(word: Word) -> List[Word]:\n",
        "    size = len(word)\n",
        "    trigrams = [''.join(ngram) for ngram in ngrams(f'${word}$', 3)]\n",
        "    wrds = Counter()\n",
        "    for wlen in range(max(size - 2, 1), size + 3):\n",
        "        groups = index.get(wlen, {})\n",
        "        for tgram in trigrams:\n",
        "            wrds.update(Counter(groups.get(tgram, [])))\n",
        "    \n",
        "    wrds = [(wrd, cnt) for wrd, cnt in wrds.items()]\n",
        "    wrds = sorted(wrds, key=lambda x: -x[1])\n",
        "    \n",
        "    return [wrd for wrd, cnt in wrds]\n",
        "\n",
        "\n",
        "for original, fixed in words_to_fix[:5]:\n",
        "    similar = find_similar_words(original)\n",
        "    print(original, fixed, '- ok' if fixed in similar else '- fail')\n",
        "    for word in similar[:5]:\n",
        "        print(' ', word)\n",
        "    print()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chothes clothes - ok\n",
            "  rothes\n",
            "  clothes\n",
            "  soothes\n",
            "  chota\n",
            "  choti\n",
            "\n",
            "cataloges catalogs - ok\n",
            "  cataloged\n",
            "  catalogues\n",
            "  catalogers\n",
            "  catalog\n",
            "  catalogs\n",
            "\n",
            "compond compound - ok\n",
            "  compound\n",
            "  component\n",
            "  compo\n",
            "  compose\n",
            "  compost\n",
            "\n",
            "barns barnes - ok\n",
            "  barns\n",
            "  barnens\n",
            "  barn\n",
            "  arns\n",
            "  barne\n",
            "\n",
            "emberissing embarrassing - ok\n",
            "  embossing\n",
            "  remembering\n",
            "  embarrassing\n",
            "  dismembering\n",
            "  crisscrossing\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvkpvimXmSMD"
      },
      "source": [
        "Чтобы оценить качество полученного алгоритма, используйте запросы из `queries.tsv.gz`. Отберите только отличающиеся слова в исправленном и исходном запросах. Проверьте, что для слова в исходном запросе, исправленное слово будет в списке ближайших выданном вашим алгоритмом. Если это выполняется для всех или почти всех пар – успех. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "3RSnRgo1mVMi",
        "outputId": "b97ec14e-f443-4756-e595-958b52cd3741"
      },
      "source": [
        "def check_find_similar_words(words_to_fix: List[Tuple[Word, Word]], \n",
        "                             find_similar_words: Callable[[Word], List[Word]], \n",
        "                             debug: bool):\n",
        "    wrong, total = 0, 0\n",
        "    progress = tqdm(words_to_fix)\n",
        "    debug_output = 0\n",
        "    for word_orig, word_fixed in progress:\n",
        "        similar = find_similar_words(word_orig)\n",
        "        if word_fixed not in similar:\n",
        "            wrong += 1\n",
        "            if debug:\n",
        "                print(word_orig, word_fixed)\n",
        "                debug_output += 1\n",
        "                if debug_output == 10:\n",
        "                    break\n",
        "        total += 1\n",
        "        progress.set_description(f'Wrong: {wrong} - {wrong/total*100:0.2f}%')\n",
        "        \n",
        "check_find_similar_words(words_to_fix, find_similar_words, debug=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Wrong: 113 - 5.50%:   4%|▍         | 2056/53495 [00:35<14:52, 57.65it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3ad9ae764460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Wrong: {wrong} - {wrong/total*100:0.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcheck_find_similar_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_to_fix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_similar_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-3ad9ae764460>\u001b[0m in \u001b[0;36mcheck_find_similar_words\u001b[0;34m(words_to_fix, find_similar_words, debug)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdebug_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_fixed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msimilar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similar_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword_fixed\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mwrong\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-214aaa9e92d3>\u001b[0m in \u001b[0;36mfind_similar_words\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mwrds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mwrds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwrd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwrds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mwrds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-214aaa9e92d3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mwrds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mwrds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwrd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwrds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mwrds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5sQ0ZtSmSMF"
      },
      "source": [
        "## 3. Языковая модель\n",
        "Языковая модель – модель, которая по тексту оценивает вероятность того, что он мог появиться в языке. \n",
        "\n",
        "Постройте простую n-грамную языковую модель с использованием корпуса текстов `train.bz2`. Для этого рассчитайте количество вхождений каждой n-граммы в корпус текста. Если взять n=2, то размера оперативной памяти вашего компьютера должно будет хватить.\n",
        "\n",
        "Воспользуйтесь каким-нибудь методом сглаживания, чтобы не получать нулевую вероятность для неизвестных n-грамм. Также, чтобы вероятности слов, которых нет в словаре, были отличны от нуля, можно примешать побуквенную m-граммную модель.\n",
        "\n",
        "Совет N: если количество оперативной памяти прижмёт, можно хранить строки в виде байт – один раскодированный символ занимает больше памяти чем один байт, при этом для английского текста почти всегда один символ кодируется одним байтом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngpe5N5rpsi-"
      },
      "source": [
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "def get_model(sentences):\n",
        "    unigrms = defaultdict(lambda: 0)\n",
        "    bigrms = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "    ttl = 0\n",
        "    ttlb = 0\n",
        "    for sentence in tqdm(sentences):\n",
        "        for w1 in sentence.split():\n",
        "            unigrms[w1.lower()] += 1\n",
        "            ttl += 1\n",
        "        for w1, w2 in bigrams(sentence.split()):\n",
        "            bigrms[w1.lower()][w2.lower()] += 1\n",
        "            ttlb += 1\n",
        "\n",
        "    for w1 in tqdm(unigrms):\n",
        "        unigrms[w1.lower()] /= ttl\n",
        "    for w1 in tqdm(bigrms):\n",
        "        for w2 in bigrms[w1.lower()]:\n",
        "            bigrms[w1.lower()][w2.lower()] /= ttlb\n",
        "    return unigrms, bigrms"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ci23bVvtuF9",
        "outputId": "413e7e59-87c5-4f32-e4e6-f21d93d60541"
      },
      "source": [
        "sentences = [line for line in read_huge_corpus(\"./drive/MyDrive/train.bz2\")]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4717753it [00:35, 132536.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MT0enJft4tA",
        "outputId": "b1e19ff8-ae86-4444-e8ab-b2dc52419e6a"
      },
      "source": [
        "unigrms, bigrms = get_model(sentences)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4717753/4717753 [03:29<00:00, 22527.24it/s]\n",
            "100%|██████████| 1681973/1681973 [00:01<00:00, 1082020.76it/s]\n",
            "100%|██████████| 1500088/1500088 [00:12<00:00, 120478.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HihGribn_qu"
      },
      "source": [
        "unigrms = {word:cnt for word, cnt in unigrms.items() if word in dct}"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vum8TtLPoTlW"
      },
      "source": [
        "bigrms = {word:cnt for word, cnt in bigrms.items() if word in dct}"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-hyRAFryOtR"
      },
      "source": [
        "def get_mgrams(sentences):\n",
        "    mgrams = defaultdict(lambda: 0)\n",
        "    ttl = 0\n",
        "    for sentence in tqdm(sentences):\n",
        "        for word in sentence.split():\n",
        "            w = word.lower()\n",
        "            if w in dct:\n",
        "                for ngram in ngrams(f'${w}$', 3):\n",
        "                    tgram = ''.join(ngram)\n",
        "                    mgrams[tgram] += 1\n",
        "                    ttl += 1\n",
        "    for tgram in mgrams:\n",
        "        mgrams[tgram] /= ttl\n",
        "    return dict(mgrams)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lr7y5n71Sp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b6a4e0-03b9-490d-9792-9bb76509412f"
      },
      "source": [
        "tgrams = get_mgrams(sentences)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4717753/4717753 [07:22<00:00, 10666.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pggqtsGUCNqd",
        "outputId": "a89be037-3a54-4c1f-b78d-8792fcee3724"
      },
      "source": [
        "cnt = 0\n",
        "for tgram in tgrams:\n",
        "    print(tgram, tgrams[tgram])\n",
        "    if cnt > 10:\n",
        "        break\n",
        "    cnt += 1"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$go 0.000543188731663703\n",
            "gol 0.00010343088474842835\n",
            "ol$ 0.00046026836305345834\n",
            "$ne 0.0010225178800616233\n",
            "nes 0.0005390644062852137\n",
            "esh 9.98250762231679e-05\n",
            "shi 0.0006792068133410809\n",
            "hin 0.0005144295647685407\n",
            "in$ 0.007964045850921527\n",
            "$mi 0.0009877455049654947\n",
            "mit 0.00022649927256582832\n",
            "ito 0.00014170324860385237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vmy9zwSp-Gp"
      },
      "source": [
        "def get_probability(query: Query) -> float:\n",
        "    probability = 0\n",
        "    words = [word.lower() for word in query.split()]\n",
        "    for w1, w2 in bigrams(words):\n",
        "        score = bigrms.get(w1, {}).get(w2, 0)\n",
        "        if score > 0:\n",
        "            probability += 1\n",
        "        else:\n",
        "            probability -= 1\n",
        "            for w in (w1, w2):\n",
        "                if w not in unigrms:\n",
        "                    # for ngram in ngrams(f'${w}$', 3):\n",
        "                    #     tgram = ''.join(ngram)\n",
        "                    #     if tgram not in tgrams:\n",
        "                    #         probability -= 1\n",
        "                # else:\n",
        "                    probability -= 1\n",
        "                \n",
        "    return probability"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-MArxf4mSMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe33c5c-9cd1-4093-d092-251fcaf8f855"
      },
      "source": [
        "# def get_probability(query: Query) -> float:\n",
        "#     probability = 0\n",
        "#     words = [word.lower() for word in query.split()]\n",
        "#     for w1, w2 in bigrams(words):\n",
        "#         probability += bigrms.get(w1, {}).get(w2, 0)\n",
        "#         probability += unigrms.get(w1, 0) + unigrms.get(w2, 0)\n",
        "#         score = 1\n",
        "#         # for ngram in ngrams(f'${w1}$', 3):\n",
        "#         #     tgram = ''.join(ngram)\n",
        "#         #     probability += tgrams.get(tgram, 0)\n",
        "#     return probability\n",
        "\n",
        "for original, fixed in queries_sample:\n",
        "    p_original = get_probability(original)\n",
        "    p_fixed = get_probability(fixed)\n",
        "    verdict = '[ok]  ' if p_fixed > p_original else '[fail]'\n",
        "    sign = '< ' if p_fixed > p_original else '>='\n",
        "    print(f'{verdict} {original:>40s} {p_original:5.2f}  {sign} {p_fixed:5.2f} {fixed}')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok]                          grand theift auto  0.00  <   0.00 grand theft auto\n",
            "[ok]             belarus longitude and latitdue  0.06  <   0.06 belarus longitude and latitude\n",
            "[ok]                          search for poeoms  0.02  <   0.02 search for poems\n",
            "[ok]      large guacolmoi dip restaurtant price  0.00  <   0.00 large guacamole dip restaurant price\n",
            "[ok]                    texas chainsaw mascurer  0.00  <   0.00 texas chainsaw massacre\n",
            "[fail]                     royal trump subtitle  0.00  >=  0.00 royal tramp subtitle\n",
            "[ok]                   florida fiberglass polls  0.00  <   0.00 florida fiberglass pools\n",
            "[ok]                     how to make a calender  0.08  <   0.08 how to make a calendar\n",
            "[ok]               university of south caroline  0.07  <   0.07 university of south carolina\n",
            "[fail]             maureen mcdonald in virginia  0.07  >=  0.07 maureen mcdonnell in virginia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB54sAAymSMG"
      },
      "source": [
        "Чтобы оценить качество полученной модели, используйте запросы из `queries.tsv.gz`. Сравните вероятность, которую выдает ваша модель для исходных и исправленных запросов. Хорошая модель выдаёт исправленному запросу большую вероятность. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhJbaqjJmSMJ"
      },
      "source": [
        "Советую сохранить полученную модель на диск – а случае чего, чтение статистик с диска, может быть быстрее расчёта оных с нуля."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAB8kjyed27s",
        "outputId": "290355ff-a8d1-4726-9c2e-f2931f3979ee"
      },
      "source": [
        "def check_language_model(queries: Queries, get_probability: Callable[[Query], float], debug: bool):\n",
        "    wrong, total = 0, 0\n",
        "    progress = tqdm(queries)\n",
        "    debug_output = 0\n",
        "    for original, fixed in progress:\n",
        "        if original == fixed:\n",
        "            continue\n",
        "        p_original = get_probability(original)\n",
        "        p_fixed = get_probability(fixed)\n",
        "        if p_fixed <= p_original:\n",
        "            wrong += 1\n",
        "            if debug:\n",
        "                print(original, p_original)\n",
        "                print(fixed, p_fixed)\n",
        "                print()\n",
        "                debug_output += 1\n",
        "                if debug_output == 10:\n",
        "                    break\n",
        "        total += 1\n",
        "        progress.set_description(f'Wrong: {wrong} - {wrong/total*100:0.2f}%')\n",
        "        \n",
        "check_language_model(queries, get_probability, debug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Wrong: 2329 - 4.54%: 100%|██████████| 102436/102436 [01:57<00:00, 870.38it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "9GogDr3kUWww",
        "outputId": "dc7835b9-4d31-4b9f-8f9e-bee794534882"
      },
      "source": [
        "def check_language_model(queries: Queries, get_probability: Callable[[Query], float], debug: bool):\n",
        "    wrong, total = 0, 0\n",
        "    progress = tqdm(queries)\n",
        "    debug_output = 0\n",
        "    for original, fixed in progress:\n",
        "        if original == fixed:\n",
        "            continue\n",
        "        p_original = get_probability(original)\n",
        "        p_fixed = get_probability(fixed)\n",
        "        if p_fixed <= p_original:\n",
        "            wrong += 1\n",
        "            if debug:\n",
        "                print(original, p_original)\n",
        "                print(fixed, p_fixed)\n",
        "                print()\n",
        "                debug_output += 1\n",
        "                if debug_output == 10:\n",
        "                    break\n",
        "        total += 1\n",
        "        progress.set_description(f'Wrong: {wrong} - {wrong/total*100:0.2f}%')\n",
        "        \n",
        "check_language_model(queries, get_probability, debug=False)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Wrong: 533 - 9.22%:  11%|█▏        | 11635/102436 [00:11<01:32, 977.23it/s] \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-37170eaf9454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Wrong: {wrong} - {wrong/total*100:0.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcheck_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-82-37170eaf9454>\u001b[0m in \u001b[0;36mcheck_language_model\u001b[0;34m(queries, get_probability, debug)\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Wrong: {wrong} - {wrong/total*100:0.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcheck_language_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mset_description\u001b[0;34m(self, desc, refresh)\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_description_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 )\n\u001b[1;32m    546\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYOARm4gmSMJ"
      },
      "source": [
        "### 4. Модель ошибок\n",
        "Модель ошибок – модель которая по исходному и исправленному запросу оценивает вероятность того, что такая ошибка могла быть допущена.\n",
        "\n",
        "Рассчитайте простую модель ошибок на основе расстояния Дамерау-Левенштейна, то есть модифицированного Левенштейна, который считает перестановку соседних букв за одну ошибку."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMgXI5PWHAce",
        "outputId": "0dc2a570-01c1-45c9-84a2-9a5a75f58e99"
      },
      "source": [
        "!pip install fastDamerauLevenshtein"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastDamerauLevenshtein in /usr/local/lib/python3.7/dist-packages (1.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY2t_761JZlo"
      },
      "source": [
        "from fastDamerauLevenshtein import damerauLevenshtein"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkG5Hbg7w-Mg"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oRU4Vd_mSMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1b4972-4106-4020-9da9-363e295286fd"
      },
      "source": [
        "def get_error_probability(original: Query, fixed: Query) -> float:\n",
        "    dist = damerauLevenshtein(original, fixed, similarity=False, \n",
        "                              deleteWeight=1,\n",
        "                              insertWeight=1, \n",
        "                              replaceWeight=1,\n",
        "                              swapWeight=1)   \n",
        "    return 1 if dist == 0 else 1.3 ** -dist\n",
        "\n",
        "for original, fixed in queries_sample:\n",
        "    p_error = get_error_probability(original, fixed)\n",
        "    print(f'{original:>40s} | {p_error:5.2f} | {fixed}')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       grand theift auto |  0.77 | grand theft auto\n",
            "          belarus longitude and latitdue |  0.77 | belarus longitude and latitude\n",
            "                       search for poeoms |  0.77 | search for poems\n",
            "   large guacolmoi dip restaurtant price |  0.27 | large guacamole dip restaurant price\n",
            "                 texas chainsaw mascurer |  0.35 | texas chainsaw massacre\n",
            "                    royal trump subtitle |  0.77 | royal tramp subtitle\n",
            "                florida fiberglass polls |  0.77 | florida fiberglass pools\n",
            "                  how to make a calender |  0.77 | how to make a calendar\n",
            "            university of south caroline |  0.77 | university of south carolina\n",
            "            maureen mcdonald in virginia |  0.46 | maureen mcdonnell in virginia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiwnA9CHmSMK"
      },
      "source": [
        "## 5. Всё вместе (1 балл)\n",
        "Объедините результат работы предыдущих пунктов в единый алгоритм исправления опечатки для запроса.\n",
        "\n",
        "Примерный план:\n",
        "1.\tДля слов запроса генерируем список ближайших слов-кандидатов (для всех, даже словарных слов).\n",
        "2.\tСобираем список кандидатов-запросов (эвристически, чтобы не сделать экспоненциальное время выполнения)\n",
        "3.\tДля каждого кандидата считаем итоговый объединенный score на основе языковой модели и модели ошибок для данного кандидата (не обязательно сумма или произведение, можно объединение любой сложности).\n",
        "4.\tВыдаём гипотезу с наибольшим score.\n",
        "5.\t???\n",
        "6.\tProfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dyfymz1NwHt"
      },
      "source": [
        "from itertools import product"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccMJ9xcDmSML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ddce5c-3cc4-4635-824f-b5c42d33686b"
      },
      "source": [
        "def correct(query: Query) -> Query:\n",
        "    words = query.split()\n",
        "    similar_words = []\n",
        "    for word in words:\n",
        "        sim_words = find_similar_words(word)\n",
        "        sim_words = [(w, get_error_probability(word, w)) for w in sim_words]\n",
        "        sim_words = sorted(sim_words, key=lambda x: -x[1])\n",
        "        similar_words.append([w for w, p in sim_words[:2]])\n",
        "    best = (1000000000, '')\n",
        "    for q in product(*similar_words):\n",
        "        qr = ' '.join(q)\n",
        "        cur = (-get_probability(qr), qr)\n",
        "        if best[0] > cur[0]:\n",
        "            best = cur\n",
        "    return best[1]\n",
        "\n",
        "for original, fixed in queries_sample:\n",
        "    predict = correct(original)\n",
        "    verdict = '[ok]  ' if predict == fixed else '[fail]'\n",
        "    sign = '==' if predict == fixed else '!='\n",
        "    print(f'{verdict} {predict:>40s} {sign} {fixed}')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ok]                           grand theft auto == grand theft auto\n",
            "[ok]             belarus longitude and latitude == belarus longitude and latitude\n",
            "[ok]                           search for poems == search for poems\n",
            "[fail]       large giacomo dip restaurant price != large guacamole dip restaurant price\n",
            "[fail]                    texas chainsaw maurer != texas chainsaw massacre\n",
            "[fail]                    royal trump subtitled != royal tramp subtitle\n",
            "[fail]                  florida fiberglass poll != florida fiberglass pools\n",
            "[fail]                  how to make a callender != how to make a calendar\n",
            "[fail]             university of south caroline != university of south carolina\n",
            "[fail]             maureen mcdonald in virginia != maureen mcdonnell in virginia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxUPWrFmmSML"
      },
      "source": [
        "Итоговое качество меряем на примерах из `queries.tsv.gz`.\n",
        "\n",
        "Для отладки проблем с качеством имеет смысл научится понимать на каком этапе теряется правильная гипотеза для каждого примера. Например, если правильное исправление есть в списке кандидатов (п. 2), но не выбирается как лучшая – стоит крутить языковую модель, модель ошибок и их объединение."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "ikc1RMXWj3ZS",
        "outputId": "0bf7f3fd-8f25-4d37-b710-9e2926db79df"
      },
      "source": [
        "def check_corrector(queries: Queries, correct: Callable[[Query], Query], debug: bool):\n",
        "    wrong, total = 0, 0\n",
        "    progress = tqdm(queries)\n",
        "    debug_output = 0\n",
        "    for original, fixed in progress:\n",
        "        predict = correct(original)\n",
        "        if predict != fixed:\n",
        "            wrong += 1\n",
        "            if debug:\n",
        "                print(original)\n",
        "                print(fixed)\n",
        "                print(predict)\n",
        "                print()\n",
        "                debug_output += 1\n",
        "                if debug_output == 10:\n",
        "                    break\n",
        "        total += 1\n",
        "        progress.set_description(f'Wrong: {wrong} - {wrong/total*100:0.2f}%')\n",
        "        \n",
        "check_corrector(queries, correct, debug=False)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Wrong: 5931 - 29.23%:  20%|█▉        | 20291/102436 [34:40<2:20:23,  9.75it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-8a9e0b278c0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Wrong: {wrong} - {wrong/total*100:0.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mcheck_corrector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-83-8a9e0b278c0a>\u001b[0m in \u001b[0;36mcheck_corrector\u001b[0;34m(queries, correct, debug)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdebug_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mwrong\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-bc55e09962c2>\u001b[0m in \u001b[0;36mcorrect\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similar_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_error_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msimilar_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-bc55e09962c2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similar_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_error_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msimilar_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-ad3ec5c8fc08>\u001b[0m in \u001b[0;36mget_error_probability\u001b[0;34m(original, fixed)\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0minsertWeight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mreplaceWeight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                               swapWeight=1)   \n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.3\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlGe0jyf1E0p"
      },
      "source": [
        "import random"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs8jfnqXmSML",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "eb4105d2-5544-4144-dc1b-268b476538b3"
      },
      "source": [
        "def check_corrector(queries: Queries, correct: Callable[[Query], Query], debug: bool):\n",
        "    wrong, total = 0, 0\n",
        "    progress = tqdm(queries)\n",
        "    debug_output = 0\n",
        "    for original, fixed in progress:\n",
        "        predict = correct(original)\n",
        "        if predict != fixed:\n",
        "            wrong += 1\n",
        "            if debug:\n",
        "                print(original)\n",
        "                print(fixed)\n",
        "                print(predict)\n",
        "                print()\n",
        "                debug_output += 1\n",
        "                if debug_output == 10:\n",
        "                    break\n",
        "        total += 1\n",
        "        progress.set_description(f'Wrong: {wrong} - {wrong/total*100:0.2f}%')\n",
        "random.shuffle(queries)\n",
        "check_corrector(queries, correct, debug=False)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Wrong: 1702 - 29.46%:   6%|▌         | 5777/102436 [10:04<2:48:27,  9.56it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-06bcf1744a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Wrong: {wrong} - {wrong/total*100:0.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mcheck_corrector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-85-06bcf1744a04>\u001b[0m in \u001b[0;36mcheck_corrector\u001b[0;34m(queries, correct, debug)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdebug_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mwrong\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-bc55e09962c2>\u001b[0m in \u001b[0;36mcorrect\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similar_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_error_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msimilar_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-bc55e09962c2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similar_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_error_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0msim_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msimilar_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-ad3ec5c8fc08>\u001b[0m in \u001b[0;36mget_error_probability\u001b[0;34m(original, fixed)\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0minsertWeight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mreplaceWeight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                               swapWeight=1)   \n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.3\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSiFnMBulzzq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}